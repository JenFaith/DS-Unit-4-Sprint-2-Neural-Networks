{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Autograded Notebook (Canvas & CodeGrade)\n",
    "\n",
    "This notebook will be automatically graded. It is designed to test your answers and award points for the correct answers. Following the instructions for each Task carefully.\n",
    "Instructions\n",
    "\n",
    "- **Download** this notebook as you would any other ipynb file \n",
    "- **Upload** to Google Colab or work locally (if you have that set-up)\n",
    "- **Delete** `raise NotImplementedError()`\n",
    "\n",
    "- **Write** your code in the `# YOUR CODE HERE` space\n",
    "\n",
    "\n",
    "- **Execute** the Test cells that contain assert statements - these help you check your work (others contain hidden tests that will be checked when you submit through Canvas)\n",
    "\n",
    "- **Save** your notebook when you are finished\n",
    "- **Download** as a ipynb file (if working in Colab)\n",
    "- **Upload** your complete notebook to Canvas (there will be additional instructions in Slack and/or Canvas)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## *Data Science Unit 4 Sprint 2*\n",
    "\n",
    "# Sprint Challenge - Neural Network Foundations\n",
    "\n",
    "Table of Problems\n",
    "\n",
    "1. [Defining Neural Networks](#Q1)\n",
    "2. [Simple Perceptron](#Q2)\n",
    "    - Perceptron\n",
    "    - Multilayer Perceptron (i.e. Neural Network)\n",
    "    - Analyze and Compare\n",
    "4. [Keras MMP](#Q3)\n",
    "\n",
    "\n",
    "____\n",
    "\n",
    "# Before you submit your notebook you must first\n",
    "\n",
    "1) Restart your notebook's Kernal\n",
    "\n",
    "2) Run all cells sequentially, from top to bottom, so that cell numbers are sequential numbers (i.e. 1,2,3,4,5...)\n",
    "- Easiest way to do this is to click on the **Cell** tab at the top of your notebook and select **Run All** from the drop down menu. \n",
    "\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a2d017ba3200be3890c0b67eda283c48",
     "grade": false,
     "grade_id": "cell-621a8b86bacf295a",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "<a id=\"Q1\"></a>\n",
    "## 1. Defining Neural Networks \n",
    "\n",
    "Write *your own* definitions for the following terms:\n",
    "\n",
    "- **Neuron:**\n",
    "\n",
    "- **Input Layer:** \n",
    "\n",
    "- **Hidden Layer:** \n",
    "\n",
    "- **Output Layer:**\n",
    "\n",
    "- **Activation:** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Neuron:**\n",
    "Neurons (also called nodes) are mathematical structures designed to mimic the biological structure of a neuron. In basic terms, neurons are mathematical functions that accept numerical data inputs, take the sum of inputs (along with their weight and any existing biases), run this sum through an activation function, and give an output. The most basic type of a neuron is a perceptron which are neurons/nodes with only two potential outputs.\n",
    "\n",
    "- **Input Layer:** \n",
    "The input layer of a neural network consists of the data variables you are trying to classify. It assigns weights to each variable (if there are weights) and then directs the data variables to neurons in either a hidden layer or the output layer.\n",
    "\n",
    "- **Hidden Layer:** \n",
    "Hidden Layer: Hidden layers are used as an extra way of adding learning accuracy when data variables are not linearly separable. By linearly separable, I mean when two data variables, say x and y, can clearly be split into separate sections without overlap. The geometrically rigorous way of describing this would be to say that the intersection of the convex hull of each variable category is empty. But back to hidden layers. I kind of think of these hidden layers as like the middle chapters of a choose your own adventure book. They add more complexity and options for how data will ultimately be classified. Each hidden layer looks at a piece of the data you are feeding it, and then gives an output to the following layer. This allows the neural network to be more precise in its classifications. \n",
    " \n",
    "\n",
    "- **Output Layer:**\n",
    "Output Layer: The output layer is the final layer in a neural network. This is the final layer of neurons the data is run through that ultimately makes a prediction on the classification of the variables.\n",
    "\n",
    "\n",
    "- **Activation:** \n",
    "Activation: Activation functions are the brilliant way that neurons decide how to output data. Essentially, your neuron holds an activation function that the data is fed through. The sigmoid function is often used. If the data output is above a certain threshold (for example 0.6 or 0.8), the neuron gives one output. Some activation functions like the linear activation function (A=cx) allow for multiple outputs while others like the sigmoid function just allow for a 0 or 1 output. Others like the softmax function are able to classify an input into multiple categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7233c31461609b21a7fc2651afb12632",
     "grade": true,
     "grade_id": "cell-6adae65226f09553",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7783735fe8826a843400b04f69084a54",
     "grade": false,
     "grade_id": "cell-d64f1de9e9458dc7",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "- `Explain` how Backpropagation works \n",
    "- `Explain` how Gradient Descent works (mention the learning rate)\n",
    "- `Explain` how Backpropagation and Gradient Descent are related   \n",
    "\n",
    "Use your own words, but feel free to reference external materials for this question. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Backpropagation:\n",
    "\n",
    "Backpropgation is the way in which neural networks update their weight and biases to give a more accurate prediction of variables. This is done by finding the partial derivative of the cost function.\n",
    "\n",
    "\n",
    "- Gradient Descent:\n",
    "\n",
    "Gradients report back the rate of change in outputs of a function if the inputs are changed. The slope of a line is a basic type of gradient. For neural networking, gradient descent is the process of using this principle to find the smallest cost function (or most accurate prediction). It does this by incrementally testing values and then stepping towards the direction that has the highest gradient descent. This is done mathematically by subtracting the gradient of steepest descent from the value the gradients were currently calculated from. The size of the steps it takes are determined by the learning rate which is set by us as the model creators. As gradient descent takes place, it will continue to take steps towards the place of the lowest cost function with graphically ends up being a local minimum. There's no guarantee the model will find the global minimum since it depends on where the first value is sampled from and how many local minimum exist.\n",
    "\n",
    "\n",
    "- How Backpropagation and Gradient Descent are related   \n",
    "\n",
    "In order to find the most accurate model, you want to find the smallest cost function and then update the weights and biases to give you that result. Gradient descent helps to find the minimum cost function (process explained above) and then backpropogation uses the partial derivative of that function to update weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ceb3f64a4b1b18346decf75c8f5567d2",
     "grade": true,
     "grade_id": "cell-cef20b23d4e0b056",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e040f3ddce6eb34b017f0eb685b202e6",
     "grade": false,
     "grade_id": "cell-e013d19857352d79",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "Remember our Simple Perceptron Class from Monday. \n",
    "\n",
    "- Describe the process of making a prediction, i.e. how do you go from inputs to outputs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d746de6391012340f8548821850a621c",
     "grade": true,
     "grade_id": "cell-53c7cc36db9d7983",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "I think I explained a bit of this already in my explanation above, but, to summarize, you start by calculating the weighted sum of all inputs and adding in a bias if one exists. Then, you put that output through a activation function (on monday we used the sigmoid function) which gives you an output value. In Monday's example, it gave us an output of either zero or one depending on if the threshold was met."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Q2\"></a>\n",
    "## 2. Simple Perceptron\n",
    "\n",
    "In this question, you will build two neural networks using `Keras`. After you build these two models, compare the results of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Our Dataset\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "rng = np.random.RandomState(0)\n",
    "\n",
    "\"Use this X & y in the following 2 models\"\n",
    "X = rng.randn(300, 2)\n",
    "y = np.array(np.logical_xor(X[:, 0] > 0, X[:, 1] > 0), \n",
    "             dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize data pre model\n",
    "max = X.max()\n",
    "X = X/max\n",
    "X.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Perceptron\n",
    "Construct a simple perceptron using Keras. \n",
    "\n",
    "Make sure to include the following in your model:\n",
    "- Add `1 dense layer` with a `single neuron` \n",
    "- Use a `sigmoid activation function`\n",
    "- Set `epochs` to 10 \n",
    "- Use the version of `crossentropy loss` that is appropriate for this data.\n",
    "\n",
    "Your model should be called `model1` and make sure to save the results of your fit statement to a variable called `h1`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "67e9f7297eb22a79437494d713d74b71",
     "grade": false,
     "grade_id": "cell-427690628f9c900b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6987 - accuracy: 0.4664\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 954us/step - loss: 0.6987 - accuracy: 0.4673\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6972 - accuracy: 0.4693\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 960us/step - loss: 0.6927 - accuracy: 0.4918\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.4574\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6909 - accuracy: 0.4929\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 910us/step - loss: 0.6908 - accuracy: 0.4905\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6945 - accuracy: 0.4406\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6954 - accuracy: 0.4326\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6965 - accuracy: 0.4188\n"
     ]
    }
   ],
   "source": [
    "# instantiate the model\n",
    "model1 = Sequential()\n",
    "\n",
    "# single dense layer\n",
    "model1.add(Dense(1, input_dim=2, activation=\"sigmoid\"))\n",
    "\n",
    "# compile the model \n",
    "# binary crossentropy is an apporpriate crossentropy loss since\n",
    "# y is either 0 or 1\n",
    "model1.compile(loss=\"binary_crossentropy\",\n",
    "                # chose this becuase it works well for a variety of data and uses little computational power\n",
    "                optimizer=\"adam\", \n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "# fit the model \n",
    "h1 = model1.fit(X, y, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 3\n",
      "Trainable params: 3\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 765us/step - loss: 0.6929 - accuracy: 0.4400\n",
      "The accuracy of our model is 0.4399999976158142\n"
     ]
    }
   ],
   "source": [
    "scores1 = model1.evaluate(X, y)\n",
    "print('The accuracy of our model is', scores1[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4399999976158142"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores1[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "36f7f830036d0443ca8e8ba0f17b2a4e",
     "grade": true,
     "grade_id": "cell-bf2ae566afacde8c",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Visible test\n",
    "assert len(model1.get_config()[\"layers\"]) == 2, \"Make sure you only create 1 Dense layer.\"\n",
    "assert len(h1.epoch) <=10, \"Did you make sure to set epochs to 10 or less?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "95d3ee2935a0de64f2a5a22460520e69",
     "grade": true,
     "grade_id": "cell-a957e14380b2f508",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Hidden tests - you will see the results when you submit to Canvas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Layer Perceptron\n",
    "Now construct a multi-layer perceptron model (also known as a neural network). \n",
    "\n",
    "Your neural network `must` have: \n",
    "- `2` Hidden Layers\n",
    "- Select any number between `5-32` for the number of neurons in each hidden layers\n",
    "- Your pick of activation function and optimizer\n",
    "- Incorporate the `Callback function` below into your model\n",
    "- Set epochs to `100`\n",
    "- Your model should be called `model2` \n",
    "- Save the results of your fit statement to a variable called `h2`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class didn't actually work so I edited it\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "class myCallback(tf.keras.callbacks.Callback): \n",
    "    def on_epoch_end(self, epoch, logs={}): \n",
    "        # if model reaches 80% accuracy, training is terminated \n",
    "        acc_threshold = 0.80\n",
    "        if(logs.get('accuracy') > acc_threshold):   \n",
    "            self.model.stop_training = True\n",
    "            self.model.callback_used = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "314337f29c8cd7f38224a31687a86b12",
     "grade": false,
     "grade_id": "cell-77523c4c64743f16",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "10/10 [==============================] - 1s 1ms/step - loss: 0.7327 - accuracy: 0.4735\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6897 - accuracy: 0.5561\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6909 - accuracy: 0.5139\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6923 - accuracy: 0.5347\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6890 - accuracy: 0.5467\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6969 - accuracy: 0.4857\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6976 - accuracy: 0.5371\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.5305\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6919 - accuracy: 0.4811\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6905 - accuracy: 0.5770\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6900 - accuracy: 0.6049\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6873 - accuracy: 0.5135\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6854 - accuracy: 0.6684\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6915 - accuracy: 0.4797\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6824 - accuracy: 0.6099\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6895 - accuracy: 0.4820\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6700 - accuracy: 0.6094\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6833 - accuracy: 0.5973\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6747 - accuracy: 0.6731\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6622 - accuracy: 0.6765\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6555 - accuracy: 0.6490\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6483 - accuracy: 0.6285\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6444 - accuracy: 0.6748\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6212 - accuracy: 0.6759\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5983 - accuracy: 0.7178\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6011 - accuracy: 0.7120\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5930 - accuracy: 0.7103\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6012 - accuracy: 0.6666\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5838 - accuracy: 0.6758\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5582 - accuracy: 0.6886\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5678 - accuracy: 0.6852\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5358 - accuracy: 0.7835\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5275 - accuracy: 0.7182\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5289 - accuracy: 0.7693\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4980 - accuracy: 0.7929\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4905 - accuracy: 0.8113\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.4735 - accuracy: 0.7910\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4716 - accuracy: 0.8094\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4938 - accuracy: 0.7615\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5006 - accuracy: 0.7704\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4786 - accuracy: 0.7765\n"
     ]
    }
   ],
   "source": [
    "# instantiate the model\n",
    "model2 = Sequential()\n",
    "\n",
    "# tested variety of neurons. This was the \n",
    "# first dense layer\n",
    "model2.add(Dense(32, input_dim=2, activation=\"sigmoid\"))\n",
    "\n",
    "# second dense layer\n",
    "model2.add(Dense(20, input_dim=2, activation=\"sigmoid\"))\n",
    "\n",
    "# third dense layer\n",
    "model2.add(Dense(1, input_dim=2, activation=\"sigmoid\"))\n",
    "\n",
    "\n",
    "# compile the model \n",
    "# binary crossentropy is an apporpriate crossentropy loss since\n",
    "# y is either 0 or 1\n",
    "# chose this becuase it works well for a variety of data and uses little computational power\n",
    "# tested sgd and adadelta and had lower accuracy\n",
    "opt = tf.keras.optimizers.Nadam(learning_rate=0.01)\n",
    "\n",
    "model2.compile(loss=\"binary_crossentropy\",\n",
    "               optimizer=opt,\n",
    "               metrics=[\"accuracy\"])\n",
    "\n",
    "# fit the model \n",
    "h2 = model2.fit(X, y, epochs=100, callbacks=[myCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 905us/step - loss: 0.4606 - accuracy: 0.7900\n",
      "The accuracy of my second model is 0.7900000214576721\n"
     ]
    }
   ],
   "source": [
    "scores2 = model2.evaluate(X, y)\n",
    "print('The accuracy of my second model is', scores2[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4a5f575f46f151f97f1cebc19a484bae",
     "grade": true,
     "grade_id": "cell-770612ca24334d8a",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Visible test\n",
    "assert len(model2.get_config()[\"layers\"]) == 4, \"You should have 4 layers: Input, hidden 1, hidden 2, output.\"\n",
    "assert 5 <= model2.get_config()[\"layers\"][1][\"config\"][\"units\"] <= 32, \"You should have 5 - 32 units in hidden layer 1, but don't.\"\n",
    "assert 5 <= model2.get_config()[\"layers\"][2][\"config\"][\"units\"] <= 32, \"You should have 5 - 32 units in hidden layer 2, but don't.\"\n",
    "assert h2.params[\"epochs\"] == 100, \"You didn't set epochs to 100.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3ca73d4d3d17897a570e19a8a97c050f",
     "grade": true,
     "grade_id": "cell-49b1bf7cce22b5b9",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Hidden tests - you will see the results when you submit to Canvas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze and Compare\n",
    "\n",
    "**Before you Start**: You will need to install an additional library for this next segment. \n",
    "\n",
    "Install the package `mlxtend` into the environment you are using for the sprint challenge.\n",
    "\n",
    "You can install this package using the following statement in the terminal\n",
    "\n",
    "```python\n",
    "pip install mlxtend\n",
    "```\n",
    "\n",
    "Or you can install this package using the following statement in your notebook\n",
    "\n",
    "```python\n",
    "!pip install mlxtend\n",
    "```\n",
    "\n",
    "If you choose to install this package from within your notebook, be sure to delete the install statement afterwards so that CodeGrade doesn't try to install it and potentially crash. \n",
    "\n",
    "\n",
    "The cells below generate decision boundary plots of your models (`model1` & `model2`). Review the plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(12,6))\n",
    "\n",
    "for clf, hist, name, grd in zip([model1,model2], [h1, h2],['Perceptron', 'Multi-Layer Perceptron'],[1,2]):\n",
    "\n",
    "    ax = plt.subplot(1,2, grd)\n",
    "    fig = plot_decision_regions(X=X, y=y, clf=clf, legend=2)\n",
    "    title = f\"{name} with {hist.history['accuracy'][-1]:,.2f} Accuracy\"\n",
    "    plt.title(title)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0aa0ea53adb9a64cf9034fd3ed156395",
     "grade": false,
     "grade_id": "cell-b1bde9222e35b3fc",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "1) Why does the Perceptron (`model1`) only achieve about 50% accuracy? \n",
    "\n",
    "2) What is the architectural property of the Multi-Layer Perceptron that allows it to more accurately learn the relationship between X and y? \n",
    "- Hint: recall that each layer represents a vector space and they usually have a different number of dimenions, $\\mathbb{R}^N$.\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e01b50ff508342b905c5a4cdbd7d2dc4",
     "grade": true,
     "grade_id": "cell-302694c508c8da0e",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "1) We built a model in model1 for data that is linearly separable. As we can see though, our data is not linearly separble. It's impossible to get a great prediction using neural networkign and only one neural network layer.\n",
    "\n",
    "2) Multi-layer perceptrons are able to split the data along several multi-dimensional planes thus allowing for greater accuracy when predicting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Keras MMP <a id=\"Q3\"></a>\n",
    "\n",
    "- Implement a Multilayer Perceptron architecture of your choosing using the Keras library. \n",
    "- Train your model and report its baseline accuracy. \n",
    "- Then `hyperparameter tune two parameters each with no more than 2 values each`\n",
    "    - Due to limited computational resources on CodeGrade `DO NOT INCLUDE ADDITIONAL PARAMETERS OR VALUES PLEASE`\n",
    "- Report your optimized model's accuracy\n",
    "- Use the Heart Disease Dataset provided (binary classification)\n",
    "- Use an appropriate loss function for a binary classification task\n",
    "- Use an appropriate activation function on the final layer of your network.\n",
    "- Train your model using verbose output for ease of grading.\n",
    "- Use GridSearchCV to hyperparameter tune your model. \n",
    "    - **Use `n_jobs` = 1**\n",
    "- When hyperparameter tuning, show you work by adding code cells for each new experiment.\n",
    "- Report the accuracy for each combination of hyperparameters as you test them so that we can easily see which resulted in the highest accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(303, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>136</td>\n",
       "      <td>196</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>171</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>243</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>137</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>140</td>\n",
       "      <td>335</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>158</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>302</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>151</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "128   52    0   2       136   196    0        0      169      0      0.1   \n",
       "12    49    1   1       130   266    0        1      171      0      0.6   \n",
       "23    61    1   2       150   243    1        1      137      1      1.0   \n",
       "177   64    1   2       140   335    0        1      158      0      0.0   \n",
       "51    66    1   0       120   302    0        0      151      0      0.4   \n",
       "\n",
       "     slope  ca  thal  target  \n",
       "128      1   0     2       1  \n",
       "12       2   0     2       1  \n",
       "23       1   0     2       1  \n",
       "177      2   0     2       0  \n",
       "51       1   0     2       1  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# load data\n",
    "data_path = 'https://raw.githubusercontent.com/ryanleeallred/datasets/master/heart.csv'\n",
    "df = pd.read_csv(data_path)\n",
    "df = df.sample(frac=1)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "22de1dc5d17d7a0bc674d082c33e8b65",
     "grade": false,
     "grade_id": "cell-85dc40f19f5a1d6b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(303, 13)\n",
      "(303,)\n"
     ]
    }
   ],
   "source": [
    "# Create an input matrix named 'X' store it in a 2D numpy array\n",
    "\n",
    "# drop out target column & create array\n",
    "X = df.drop('target', axis = 1).to_numpy()\n",
    "\n",
    "# normalize X and verify shape\n",
    "max = X.max()\n",
    "X = X.astype('float')/max\n",
    "print(X.shape)\n",
    "\n",
    "# Create an output vector for the labels named 'Y', store it in 1D numpy array\n",
    "Y = df['target'].to_numpy()\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "825d4f808810a2a8d6301d7453afe478",
     "grade": true,
     "grade_id": "cell-c17c686c974edc2e",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Visible Testing\n",
    "assert X.shape[0] == 303, \"Did you drop/lose some rows in X? Did you properly load and split the data?\"\n",
    "assert X.shape[1] == 13, \"Did you drop/lose some columns in X? Did you properly load and split the data?\"\n",
    "assert len(Y)== 303, \"Did you drop/lose some rows in Y? Did you properly load and split the data?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "475835631ff6a34028443dbf604bd922",
     "grade": false,
     "grade_id": "cell-cfc5517cd0b6fa64",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Create a function named 'create_model' that returns a complied keras model -  required for KerasClassifier\n",
    "\n",
    "def create_model(units_1=128, units_2=60, lr=0.01):\n",
    "\n",
    "    # instaniate a Sequential object\n",
    "    model = tf.keras.Sequential()\n",
    "    \n",
    "    # hidden layer 1\n",
    "    model.add(Dense(units_1, input_dim=13, activation=\"sigmoid\"))\n",
    "    \n",
    "    # hidden layer 2\n",
    "    model.add(Dense(units_2, input_dim=13, activation=\"sigmoid\"))\n",
    "    \n",
    "    # add output layer \n",
    "    model.add(Dense(1, activation = \"sigmoid\"))\n",
    "    \n",
    "    opt = keras.optimizers.Adam(learning_rate=lr)\n",
    "    \n",
    "    # complie the model \n",
    "    model.compile(loss=\"binary_crossentropy\", \n",
    "                  optimizer=opt,\n",
    "                  metrics=[\"accuracy\"])\n",
    "    \n",
    "    # return the model \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7b906697afb0a3b52cd19e9548eae6a7",
     "grade": true,
     "grade_id": "cell-fac25126eaf1eee4",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Visible Testing\n",
    "assert create_model().__module__ == 'tensorflow.python.keras.engine.sequential', \"create_model should return a keras model that was created using the Sequential class.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0412c74b7803790452d4914d99995dd2",
     "grade": false,
     "grade_id": "cell-fbc3d0a07230078c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Pass 'create_model' into KerasClassifier, store KerasClassifier to a variable named 'model'\n",
    "model = KerasClassifier(build_fn=create_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9128 - accuracy: 0.4836\n"
     ]
    }
   ],
   "source": [
    "base = model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy is 0.4979\n"
     ]
    }
   ],
   "source": [
    "print(\"Baseline accuracy is 0.4979\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0442c29a94065e922c5ae929976a52ab",
     "grade": true,
     "grade_id": "cell-464e7506993775f2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Visible Testing\n",
    "assert model.__module__ == 'tensorflow.python.keras.wrappers.scikit_learn', \"model should be a instance of KerasClassifier.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f88603ef37a4d3d2ef8699a41ac9a0b2",
     "grade": false,
     "grade_id": "cell-985c0425f3b1304d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Define the grid search parameters inside a dictionary named 'param_grid' \n",
    "# Use 2 hyper-parameters with 2 possible values for each \n",
    "\n",
    "param_grid = {'batch_size': [32, 64],\n",
    "              'epochs': [50, 100]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment 2\n",
    "param_grid = {'batch_size': [32, 64],\n",
    "              'epochs': [100, 150]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment 3\n",
    "# learning rate of 0.01 was the best\n",
    "param_grid = {'batch_size': [15, 32],\n",
    "              'lr': [0.01, 0.1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment 4\n",
    "# best combination was 32 & 10 but that made overall score drop so i changed it back\n",
    "param_grid = {'units_1': [32, 20],\n",
    "              'units_2': [20, 10]}\n",
    "\n",
    "#Best: 0.523809532324473 using {'units_1': 32, 'units_2': 20}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment 5\n",
    "# best combination was 32 & 10 but that made overall score drop so i changed it back\n",
    "param_grid = {'units_1': [128, 80],\n",
    "              'units_2': [60, 40]}\n",
    "\n",
    "# Best: 0.523809532324473 using {'units_1': 128, 'units_2': 60}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment 6\n",
    "# best combination was 32 & 10 but that made overall score drop so i changed it back\n",
    "param_grid = {'units_1': [128, 32],\n",
    "              'units_2': [60, 20]}\n",
    "\n",
    "# Best: 0.523809532324473 using {'units_1': 128, 'units_2': 60}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment 7\n",
    "# best combination was 32 & 10 but that made overall score drop so i changed it back\n",
    "param_grid = {'units_1': [700, 130],\n",
    "              'units_2': [200, 60]}\n",
    "\n",
    "# Best: 0.523809532324473 using {'units_1': 130, 'units_2': 200}\n",
    "# doesn't actually perform well overall though"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment 5\n",
    "param_grid = {'batch_size': [15, 32],\n",
    "              'epochs': [80, 100]}\n",
    "\n",
    "# Best:  0.7357478141784668 using {'batch_size': 15, 'epochs': 100}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a551fd8278b30c1318c036f6ad43b503",
     "grade": true,
     "grade_id": "cell-c765b5db5489d7a2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert len(param_grid.keys()) == 2, \"Did you create a param dict with 2 hyper-parameters as keys?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2ea6312f4bc1f42809196b696037dd52",
     "grade": false,
     "grade_id": "cell-7cfb4315eab5031c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Create Grid Search object and name it 'gs'\n",
    "# Run Grid Search \n",
    "\n",
    "gs = GridSearchCV(estimator=model,\n",
    "                  param_grid=param_grid, \n",
    "                  n_jobs= 1,\n",
    "                  verbose=1,\n",
    "                  cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "Epoch 1/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.8020 - accuracy: 0.4805\n",
      "Epoch 2/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.8300 - accuracy: 0.4539\n",
      "Epoch 3/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7061 - accuracy: 0.4707\n",
      "Epoch 4/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6939 - accuracy: 0.5035\n",
      "Epoch 5/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5412\n",
      "Epoch 6/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6969 - accuracy: 0.4842\n",
      "Epoch 7/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.7026 - accuracy: 0.5450\n",
      "Epoch 8/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.7143 - accuracy: 0.4499\n",
      "Epoch 9/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.7010 - accuracy: 0.4505\n",
      "Epoch 10/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.5910\n",
      "Epoch 11/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7054 - accuracy: 0.5164\n",
      "Epoch 12/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7054 - accuracy: 0.4425\n",
      "Epoch 13/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6859 - accuracy: 0.5621\n",
      "Epoch 14/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6995 - accuracy: 0.4641\n",
      "Epoch 15/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6934 - accuracy: 0.5014\n",
      "Epoch 16/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6924 - accuracy: 0.5034\n",
      "Epoch 17/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6923 - accuracy: 0.5114\n",
      "Epoch 18/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6975 - accuracy: 0.5076\n",
      "Epoch 19/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6949 - accuracy: 0.5150\n",
      "Epoch 20/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6948 - accuracy: 0.5135\n",
      "Epoch 21/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.4950\n",
      "Epoch 22/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6912 - accuracy: 0.5310\n",
      "Epoch 23/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6949 - accuracy: 0.5039\n",
      "Epoch 24/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6951 - accuracy: 0.5050\n",
      "Epoch 25/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.5201\n",
      "Epoch 26/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6950 - accuracy: 0.5913\n",
      "Epoch 27/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.5242\n",
      "Epoch 28/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6884 - accuracy: 0.5534\n",
      "Epoch 29/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.7008 - accuracy: 0.5454\n",
      "Epoch 30/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7016 - accuracy: 0.4865\n",
      "Epoch 31/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5308\n",
      "Epoch 32/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6912 - accuracy: 0.5352\n",
      "Epoch 33/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6914 - accuracy: 0.5681\n",
      "Epoch 34/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6928 - accuracy: 0.4709\n",
      "Epoch 35/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6889 - accuracy: 0.5489\n",
      "Epoch 36/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6889 - accuracy: 0.5607\n",
      "Epoch 37/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6892 - accuracy: 0.6265\n",
      "Epoch 38/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6847 - accuracy: 0.5492\n",
      "Epoch 39/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6910 - accuracy: 0.5863\n",
      "Epoch 40/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6919 - accuracy: 0.4956\n",
      "Epoch 41/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6912 - accuracy: 0.5084\n",
      "Epoch 42/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6875 - accuracy: 0.6163\n",
      "Epoch 43/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6994 - accuracy: 0.5112\n",
      "Epoch 44/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6842 - accuracy: 0.5178\n",
      "Epoch 45/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6802 - accuracy: 0.6250\n",
      "Epoch 46/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6729 - accuracy: 0.6308\n",
      "Epoch 47/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6714 - accuracy: 0.6060\n",
      "Epoch 48/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6660 - accuracy: 0.5907\n",
      "Epoch 49/80\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.7426 - accuracy: 0.40 - 0s 2ms/step - loss: 0.6834 - accuracy: 0.5339\n",
      "Epoch 50/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6475 - accuracy: 0.6408\n",
      "Epoch 51/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6491 - accuracy: 0.6292\n",
      "Epoch 52/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6573 - accuracy: 0.6123\n",
      "Epoch 53/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6172 - accuracy: 0.7393\n",
      "Epoch 54/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6299 - accuracy: 0.6019\n",
      "Epoch 55/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6399 - accuracy: 0.5828\n",
      "Epoch 56/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6344 - accuracy: 0.6483\n",
      "Epoch 57/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6670 - accuracy: 0.5941\n",
      "Epoch 58/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7208 - accuracy: 0.5155\n",
      "Epoch 59/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6342 - accuracy: 0.7048\n",
      "Epoch 60/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6056 - accuracy: 0.6491\n",
      "Epoch 61/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5889 - accuracy: 0.7335\n",
      "Epoch 62/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5656 - accuracy: 0.7039\n",
      "Epoch 63/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5579 - accuracy: 0.7332\n",
      "Epoch 64/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5633 - accuracy: 0.6748\n",
      "Epoch 65/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6407 - accuracy: 0.6440\n",
      "Epoch 66/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6222 - accuracy: 0.6239\n",
      "Epoch 67/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5271 - accuracy: 0.7103\n",
      "Epoch 68/80\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.5816 - accuracy: 0.6832\n",
      "Epoch 69/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5612 - accuracy: 0.6985\n",
      "Epoch 70/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6242 - accuracy: 0.6649\n",
      "Epoch 71/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5290 - accuracy: 0.7203\n",
      "Epoch 72/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5323 - accuracy: 0.7919\n",
      "Epoch 73/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5346 - accuracy: 0.7399\n",
      "Epoch 74/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4762 - accuracy: 0.7818\n",
      "Epoch 75/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4888 - accuracy: 0.7547\n",
      "Epoch 76/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6211 - accuracy: 0.7029\n",
      "Epoch 77/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6747 - accuracy: 0.6034\n",
      "Epoch 78/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5454 - accuracy: 0.7082\n",
      "Epoch 79/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5668 - accuracy: 0.6270\n",
      "Epoch 80/80\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.5519 - accuracy: 0.7185\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x153595d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6776 - accuracy: 0.6056\n",
      "Epoch 1/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.7665 - accuracy: 0.4842\n",
      "Epoch 2/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.7092 - accuracy: 0.6158\n",
      "Epoch 3/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6983 - accuracy: 0.5026\n",
      "Epoch 4/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6980 - accuracy: 0.5740\n",
      "Epoch 5/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6708 - accuracy: 0.6131\n",
      "Epoch 6/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6874 - accuracy: 0.5733\n",
      "Epoch 7/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6591 - accuracy: 0.6536\n",
      "Epoch 8/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6730 - accuracy: 0.6091\n",
      "Epoch 9/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6840 - accuracy: 0.5778\n",
      "Epoch 10/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6819 - accuracy: 0.5810\n",
      "Epoch 11/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6826 - accuracy: 0.5825\n",
      "Epoch 12/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6762 - accuracy: 0.6081\n",
      "Epoch 13/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6797 - accuracy: 0.5884\n",
      "Epoch 14/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6867 - accuracy: 0.5761\n",
      "Epoch 15/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6885 - accuracy: 0.5550\n",
      "Epoch 16/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6786 - accuracy: 0.6158\n",
      "Epoch 17/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6619 - accuracy: 0.6155\n",
      "Epoch 18/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6827 - accuracy: 0.6360\n",
      "Epoch 19/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6966 - accuracy: 0.5399\n",
      "Epoch 20/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6802 - accuracy: 0.5829\n",
      "Epoch 21/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6886 - accuracy: 0.5640\n",
      "Epoch 22/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6708 - accuracy: 0.6067\n",
      "Epoch 23/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6692 - accuracy: 0.6296\n",
      "Epoch 24/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6805 - accuracy: 0.5779\n",
      "Epoch 25/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6742 - accuracy: 0.5981\n",
      "Epoch 26/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6600 - accuracy: 0.6649\n",
      "Epoch 27/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6760 - accuracy: 0.5897\n",
      "Epoch 28/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6859 - accuracy: 0.5525\n",
      "Epoch 29/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6886 - accuracy: 0.5664\n",
      "Epoch 30/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6744 - accuracy: 0.6031\n",
      "Epoch 31/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6772 - accuracy: 0.5985\n",
      "Epoch 32/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6829 - accuracy: 0.5853\n",
      "Epoch 33/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6742 - accuracy: 0.6006\n",
      "Epoch 34/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6868 - accuracy: 0.5656\n",
      "Epoch 35/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6886 - accuracy: 0.5395\n",
      "Epoch 36/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6937 - accuracy: 0.5406\n",
      "Epoch 37/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6912 - accuracy: 0.5658\n",
      "Epoch 38/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6831 - accuracy: 0.5607\n",
      "Epoch 39/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6777 - accuracy: 0.5879\n",
      "Epoch 40/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6770 - accuracy: 0.5848\n",
      "Epoch 41/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6760 - accuracy: 0.5965\n",
      "Epoch 42/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6645 - accuracy: 0.6197\n",
      "Epoch 43/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6645 - accuracy: 0.6208\n",
      "Epoch 44/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6826 - accuracy: 0.5835\n",
      "Epoch 45/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6800 - accuracy: 0.5719\n",
      "Epoch 46/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6678 - accuracy: 0.6166\n",
      "Epoch 47/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6663 - accuracy: 0.6044\n",
      "Epoch 48/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6784 - accuracy: 0.5901\n",
      "Epoch 49/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6720 - accuracy: 0.5962\n",
      "Epoch 50/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6896 - accuracy: 0.5524\n",
      "Epoch 51/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6584 - accuracy: 0.6368\n",
      "Epoch 52/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6688 - accuracy: 0.6024\n",
      "Epoch 53/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6754 - accuracy: 0.6052\n",
      "Epoch 54/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6705 - accuracy: 0.5950\n",
      "Epoch 55/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6760 - accuracy: 0.5885\n",
      "Epoch 56/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6706 - accuracy: 0.5850\n",
      "Epoch 57/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6584 - accuracy: 0.6363\n",
      "Epoch 58/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6642 - accuracy: 0.6010\n",
      "Epoch 59/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6472 - accuracy: 0.6337\n",
      "Epoch 60/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6935 - accuracy: 0.5446\n",
      "Epoch 61/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.7057 - accuracy: 0.5873\n",
      "Epoch 62/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6978 - accuracy: 0.5344\n",
      "Epoch 63/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6721 - accuracy: 0.6312\n",
      "Epoch 64/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6381 - accuracy: 0.6471\n",
      "Epoch 65/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6812 - accuracy: 0.5517\n",
      "Epoch 66/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6786 - accuracy: 0.5557\n",
      "Epoch 67/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6816 - accuracy: 0.5679\n",
      "Epoch 68/80\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.7758 - accuracy: 0.26 - 0s 1ms/step - loss: 0.7157 - accuracy: 0.4058\n",
      "Epoch 69/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6643 - accuracy: 0.6061\n",
      "Epoch 70/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6624 - accuracy: 0.5929\n",
      "Epoch 71/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6624 - accuracy: 0.6723\n",
      "Epoch 72/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6493 - accuracy: 0.6001\n",
      "Epoch 73/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6561 - accuracy: 0.5725\n",
      "Epoch 74/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6555 - accuracy: 0.6317\n",
      "Epoch 75/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6293 - accuracy: 0.6085\n",
      "Epoch 76/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6289 - accuracy: 0.6916\n",
      "Epoch 77/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6785 - accuracy: 0.5952\n",
      "Epoch 78/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6144 - accuracy: 0.6278\n",
      "Epoch 79/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6040 - accuracy: 0.7373\n",
      "Epoch 80/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6173 - accuracy: 0.6400\n",
      "5/5 [==============================] - 0s 949us/step - loss: 0.6100 - accuracy: 0.6197\n",
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 1ms/step - loss: 0.8523 - accuracy: 0.4293\n",
      "Epoch 2/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.7113 - accuracy: 0.5269\n",
      "Epoch 3/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.7042 - accuracy: 0.5792\n",
      "Epoch 4/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6954 - accuracy: 0.4664\n",
      "Epoch 5/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6987 - accuracy: 0.5510\n",
      "Epoch 6/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6755 - accuracy: 0.5855\n",
      "Epoch 7/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6916 - accuracy: 0.5461\n",
      "Epoch 8/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6658 - accuracy: 0.6237\n",
      "Epoch 9/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7249 - accuracy: 0.4597\n",
      "Epoch 10/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6876 - accuracy: 0.5440\n",
      "Epoch 11/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6815 - accuracy: 0.6204\n",
      "Epoch 12/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6816 - accuracy: 0.5942\n",
      "Epoch 13/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6865 - accuracy: 0.5524\n",
      "Epoch 14/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7028 - accuracy: 0.5411\n",
      "Epoch 15/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6724 - accuracy: 0.6054\n",
      "Epoch 16/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6811 - accuracy: 0.5939\n",
      "Epoch 17/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7013 - accuracy: 0.4830\n",
      "Epoch 18/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.7023 - accuracy: 0.5251\n",
      "Epoch 19/80\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.6368 - accuracy: 0.66 - 0s 2ms/step - loss: 0.6828 - accuracy: 0.5858\n",
      "Epoch 20/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6761 - accuracy: 0.6056\n",
      "Epoch 21/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7189 - accuracy: 0.4023\n",
      "Epoch 22/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6823 - accuracy: 0.5942\n",
      "Epoch 23/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6803 - accuracy: 0.5865\n",
      "Epoch 24/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6836 - accuracy: 0.5951\n",
      "Epoch 25/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6840 - accuracy: 0.5692\n",
      "Epoch 26/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6843 - accuracy: 0.5708\n",
      "Epoch 27/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6760 - accuracy: 0.6095\n",
      "Epoch 28/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6799 - accuracy: 0.5814\n",
      "Epoch 29/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6796 - accuracy: 0.6332\n",
      "Epoch 30/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6781 - accuracy: 0.5856\n",
      "Epoch 31/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6864 - accuracy: 0.5749\n",
      "Epoch 32/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.7075 - accuracy: 0.5160\n",
      "Epoch 33/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6774 - accuracy: 0.5944\n",
      "Epoch 34/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.7101 - accuracy: 0.5105\n",
      "Epoch 35/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6801 - accuracy: 0.6175\n",
      "Epoch 36/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6708 - accuracy: 0.5986\n",
      "Epoch 37/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6861 - accuracy: 0.5724\n",
      "Epoch 38/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6870 - accuracy: 0.5621\n",
      "Epoch 39/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6622 - accuracy: 0.6415\n",
      "Epoch 40/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6835 - accuracy: 0.5730\n",
      "Epoch 41/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6783 - accuracy: 0.6099\n",
      "Epoch 42/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.7039 - accuracy: 0.5338\n",
      "Epoch 43/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6890 - accuracy: 0.5443\n",
      "Epoch 44/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6800 - accuracy: 0.5974\n",
      "Epoch 45/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6648 - accuracy: 0.6185\n",
      "Epoch 46/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6913 - accuracy: 0.5283\n",
      "Epoch 47/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6817 - accuracy: 0.5807\n",
      "Epoch 48/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6951 - accuracy: 0.5663\n",
      "Epoch 49/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6886 - accuracy: 0.5654\n",
      "Epoch 50/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6741 - accuracy: 0.6196\n",
      "Epoch 51/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6752 - accuracy: 0.5885\n",
      "Epoch 52/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6810 - accuracy: 0.5743\n",
      "Epoch 53/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6853 - accuracy: 0.5520\n",
      "Epoch 54/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6763 - accuracy: 0.5929\n",
      "Epoch 55/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6516 - accuracy: 0.6387\n",
      "Epoch 56/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6858 - accuracy: 0.5769\n",
      "Epoch 57/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6819 - accuracy: 0.5414\n",
      "Epoch 58/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.7359 - accuracy: 0.5006\n",
      "Epoch 59/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6893 - accuracy: 0.5287\n",
      "Epoch 60/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6895 - accuracy: 0.5552\n",
      "Epoch 61/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6771 - accuracy: 0.5826\n",
      "Epoch 62/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6737 - accuracy: 0.6050\n",
      "Epoch 63/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6760 - accuracy: 0.5761\n",
      "Epoch 64/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6686 - accuracy: 0.5904\n",
      "Epoch 65/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6688 - accuracy: 0.6109\n",
      "Epoch 66/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6879 - accuracy: 0.5267\n",
      "Epoch 67/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6750 - accuracy: 0.5608\n",
      "Epoch 68/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6690 - accuracy: 0.5832\n",
      "Epoch 69/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6692 - accuracy: 0.5576\n",
      "Epoch 70/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6587 - accuracy: 0.6067\n",
      "Epoch 71/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6702 - accuracy: 0.6389\n",
      "Epoch 72/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6575 - accuracy: 0.5718\n",
      "Epoch 73/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6523 - accuracy: 0.6168\n",
      "Epoch 74/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6559 - accuracy: 0.6703\n",
      "Epoch 75/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6981 - accuracy: 0.5216\n",
      "Epoch 76/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6609 - accuracy: 0.5765\n",
      "Epoch 77/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6890 - accuracy: 0.5696\n",
      "Epoch 78/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6456 - accuracy: 0.6946\n",
      "Epoch 79/80\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6162 - accuracy: 0.6192\n",
      "Epoch 80/80\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6622 - accuracy: 0.5298\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6621 - accuracy: 0.5143\n",
      "Epoch 1/100\n",
      "10/10 [==============================] - 1s 1ms/step - loss: 0.7188 - accuracy: 0.5465\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7703 - accuracy: 0.5026\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.7357 - accuracy: 0.4857\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6958 - accuracy: 0.5445\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.7271 - accuracy: 0.4615\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6884 - accuracy: 0.5460\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6960 - accuracy: 0.4627\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6971 - accuracy: 0.4870\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.7021 - accuracy: 0.4369\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6941 - accuracy: 0.5058\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5204\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6951 - accuracy: 0.5019\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.7007 - accuracy: 0.4405\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6965 - accuracy: 0.5159\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6895 - accuracy: 0.5390\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.5120\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.7008 - accuracy: 0.4949\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.5132\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6961 - accuracy: 0.5144\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6926 - accuracy: 0.5161\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7111 - accuracy: 0.3881\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6984 - accuracy: 0.4400\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6905 - accuracy: 0.5422\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6982 - accuracy: 0.5285\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6988 - accuracy: 0.5611\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.6872 - accuracy: 0.5397\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6925 - accuracy: 0.5287\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6953 - accuracy: 0.4875\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6927 - accuracy: 0.5413\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6948 - accuracy: 0.4635\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.5034\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6925 - accuracy: 0.5341\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6906 - accuracy: 0.5433\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.4619\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6938 - accuracy: 0.5613\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6983 - accuracy: 0.4895\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6937 - accuracy: 0.4805\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6944 - accuracy: 0.4911\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6909 - accuracy: 0.5190\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6936 - accuracy: 0.4905\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6867 - accuracy: 0.5988\n",
      "Epoch 42/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6968 - accuracy: 0.5221\n",
      "Epoch 43/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6960 - accuracy: 0.4902\n",
      "Epoch 44/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6958 - accuracy: 0.5133\n",
      "Epoch 45/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6965 - accuracy: 0.4873\n",
      "Epoch 46/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6871 - accuracy: 0.6077\n",
      "Epoch 47/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6963 - accuracy: 0.5215\n",
      "Epoch 48/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6878 - accuracy: 0.6325\n",
      "Epoch 49/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6936 - accuracy: 0.4563\n",
      "Epoch 50/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6820 - accuracy: 0.5803\n",
      "Epoch 51/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6799 - accuracy: 0.5947\n",
      "Epoch 52/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6837 - accuracy: 0.5784\n",
      "Epoch 53/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6856 - accuracy: 0.4814\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6760 - accuracy: 0.6977\n",
      "Epoch 55/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6720 - accuracy: 0.6331\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6987 - accuracy: 0.5175\n",
      "Epoch 57/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6740 - accuracy: 0.5378\n",
      "Epoch 58/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6464 - accuracy: 0.6124\n",
      "Epoch 59/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6365 - accuracy: 0.6761\n",
      "Epoch 60/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6272 - accuracy: 0.6398\n",
      "Epoch 61/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.7182 - accuracy: 0.5008\n",
      "Epoch 62/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6151 - accuracy: 0.6927\n",
      "Epoch 63/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6232 - accuracy: 0.6252\n",
      "Epoch 64/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6348 - accuracy: 0.6442\n",
      "Epoch 65/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6736 - accuracy: 0.5897\n",
      "Epoch 66/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.7415 - accuracy: 0.4691\n",
      "Epoch 67/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6694 - accuracy: 0.5399\n",
      "Epoch 68/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6576 - accuracy: 0.5920\n",
      "Epoch 69/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6357 - accuracy: 0.6323\n",
      "Epoch 70/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6215 - accuracy: 0.6431\n",
      "Epoch 71/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6150 - accuracy: 0.6908\n",
      "Epoch 72/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5820 - accuracy: 0.7202\n",
      "Epoch 73/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5678 - accuracy: 0.7093\n",
      "Epoch 74/100\n",
      "10/10 [==============================] - 0s 943us/step - loss: 0.5660 - accuracy: 0.6731\n",
      "Epoch 75/100\n",
      "10/10 [==============================] - 0s 960us/step - loss: 0.5641 - accuracy: 0.7022\n",
      "Epoch 76/100\n",
      "10/10 [==============================] - 0s 993us/step - loss: 0.5858 - accuracy: 0.7086\n",
      "Epoch 77/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5669 - accuracy: 0.6660\n",
      "Epoch 78/100\n",
      "10/10 [==============================] - 0s 977us/step - loss: 0.6028 - accuracy: 0.6858\n",
      "Epoch 79/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6278 - accuracy: 0.6615\n",
      "Epoch 80/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5486 - accuracy: 0.7054\n",
      "Epoch 81/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5435 - accuracy: 0.7520\n",
      "Epoch 82/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5074 - accuracy: 0.7395\n",
      "Epoch 83/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6500 - accuracy: 0.6125\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5563 - accuracy: 0.7447\n",
      "Epoch 85/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6763 - accuracy: 0.6395\n",
      "Epoch 86/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5789 - accuracy: 0.6924\n",
      "Epoch 87/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5206 - accuracy: 0.7540\n",
      "Epoch 88/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.4701 - accuracy: 0.7798\n",
      "Epoch 89/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.4774 - accuracy: 0.7774\n",
      "Epoch 90/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5368 - accuracy: 0.7301\n",
      "Epoch 91/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5251 - accuracy: 0.7298\n",
      "Epoch 92/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5532 - accuracy: 0.7242\n",
      "Epoch 93/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.4922 - accuracy: 0.7674\n",
      "Epoch 94/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5392 - accuracy: 0.7150\n",
      "Epoch 95/100\n",
      "10/10 [==============================] - 0s 994us/step - loss: 0.4735 - accuracy: 0.7587\n",
      "Epoch 96/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5083 - accuracy: 0.7264\n",
      "Epoch 97/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5203 - accuracy: 0.7156\n",
      "Epoch 98/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5602 - accuracy: 0.6678\n",
      "Epoch 99/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.4713 - accuracy: 0.7259\n",
      "Epoch 100/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4705 - accuracy: 0.7764\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5443 - accuracy: 0.7183\n",
      "Epoch 1/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.7310 - accuracy: 0.5359\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.7036 - accuracy: 0.4861\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7584 - accuracy: 0.5492\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6977 - accuracy: 0.6108\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7574 - accuracy: 0.4057\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6900 - accuracy: 0.5379\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6892 - accuracy: 0.5674\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6813 - accuracy: 0.5872\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6755 - accuracy: 0.5996\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6849 - accuracy: 0.5873\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6805 - accuracy: 0.5805\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6879 - accuracy: 0.5734\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6759 - accuracy: 0.6216\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6795 - accuracy: 0.5871\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6751 - accuracy: 0.6032\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6938 - accuracy: 0.5440\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6836 - accuracy: 0.5687\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6891 - accuracy: 0.5619\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6685 - accuracy: 0.6151\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6781 - accuracy: 0.5880\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6816 - accuracy: 0.5739\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6839 - accuracy: 0.5765\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6832 - accuracy: 0.5691\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6736 - accuracy: 0.6134\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6679 - accuracy: 0.6103\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6767 - accuracy: 0.5897\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6873 - accuracy: 0.5554\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6802 - accuracy: 0.5813\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6811 - accuracy: 0.5876\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6981 - accuracy: 0.5227\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 0s 917us/step - loss: 0.6823 - accuracy: 0.5790\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6398 - accuracy: 0.6679\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6491 - accuracy: 0.6579\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6827 - accuracy: 0.6265\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 0s 948us/step - loss: 0.6852 - accuracy: 0.5518\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 0s 921us/step - loss: 0.6795 - accuracy: 0.5839\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6760 - accuracy: 0.5884\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6783 - accuracy: 0.5986\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6875 - accuracy: 0.5635\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 0s 914us/step - loss: 0.6964 - accuracy: 0.5335\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6816 - accuracy: 0.5772\n",
      "Epoch 42/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6846 - accuracy: 0.5737\n",
      "Epoch 43/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6824 - accuracy: 0.5710\n",
      "Epoch 44/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6685 - accuracy: 0.6308\n",
      "Epoch 45/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6810 - accuracy: 0.5722\n",
      "Epoch 46/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6922 - accuracy: 0.5289\n",
      "Epoch 47/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6785 - accuracy: 0.5874\n",
      "Epoch 48/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.5504\n",
      "Epoch 49/100\n",
      "10/10 [==============================] - 0s 994us/step - loss: 0.6912 - accuracy: 0.5458\n",
      "Epoch 50/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6797 - accuracy: 0.5740\n",
      "Epoch 51/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6828 - accuracy: 0.5647\n",
      "Epoch 52/100\n",
      "10/10 [==============================] - 0s 953us/step - loss: 0.6918 - accuracy: 0.5379\n",
      "Epoch 53/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6764 - accuracy: 0.5711\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6936 - accuracy: 0.5586\n",
      "Epoch 55/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6844 - accuracy: 0.5134\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - 0s 926us/step - loss: 0.6708 - accuracy: 0.6060\n",
      "Epoch 57/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6446 - accuracy: 0.6383\n",
      "Epoch 58/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6900 - accuracy: 0.5250\n",
      "Epoch 59/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6935 - accuracy: 0.5310\n",
      "Epoch 60/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6684 - accuracy: 0.6031\n",
      "Epoch 61/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6620 - accuracy: 0.6057\n",
      "Epoch 62/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6686 - accuracy: 0.5905\n",
      "Epoch 63/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6775 - accuracy: 0.5338\n",
      "Epoch 64/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6562 - accuracy: 0.5992\n",
      "Epoch 65/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6670 - accuracy: 0.6892\n",
      "Epoch 66/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6424 - accuracy: 0.6160\n",
      "Epoch 67/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6629 - accuracy: 0.5675\n",
      "Epoch 68/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6693 - accuracy: 0.5904\n",
      "Epoch 69/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6397 - accuracy: 0.6651\n",
      "Epoch 70/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6101 - accuracy: 0.6567\n",
      "Epoch 71/100\n",
      "10/10 [==============================] - 0s 977us/step - loss: 0.7066 - accuracy: 0.4733\n",
      "Epoch 72/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6489 - accuracy: 0.6347\n",
      "Epoch 73/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6617 - accuracy: 0.5992\n",
      "Epoch 74/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6124 - accuracy: 0.6747\n",
      "Epoch 75/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5887 - accuracy: 0.7222\n",
      "Epoch 76/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6097 - accuracy: 0.7067\n",
      "Epoch 77/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5890 - accuracy: 0.7155\n",
      "Epoch 78/100\n",
      "10/10 [==============================] - 0s 943us/step - loss: 0.5961 - accuracy: 0.6908\n",
      "Epoch 79/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5933 - accuracy: 0.6936\n",
      "Epoch 80/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5714 - accuracy: 0.7107\n",
      "Epoch 81/100\n",
      "10/10 [==============================] - 0s 975us/step - loss: 0.5863 - accuracy: 0.6534\n",
      "Epoch 82/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5448 - accuracy: 0.7456\n",
      "Epoch 83/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5583 - accuracy: 0.7366\n",
      "Epoch 84/100\n",
      "10/10 [==============================] - 0s 959us/step - loss: 0.6195 - accuracy: 0.6726\n",
      "Epoch 85/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5359 - accuracy: 0.7357\n",
      "Epoch 86/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5353 - accuracy: 0.7554\n",
      "Epoch 87/100\n",
      "10/10 [==============================] - 0s 944us/step - loss: 0.5367 - accuracy: 0.7600\n",
      "Epoch 88/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6291 - accuracy: 0.6858\n",
      "Epoch 89/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5519 - accuracy: 0.7591\n",
      "Epoch 90/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5165 - accuracy: 0.7805\n",
      "Epoch 91/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5546 - accuracy: 0.6986\n",
      "Epoch 92/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5706 - accuracy: 0.7120\n",
      "Epoch 93/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5958 - accuracy: 0.6455\n",
      "Epoch 94/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5454 - accuracy: 0.7350\n",
      "Epoch 95/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5706 - accuracy: 0.7431\n",
      "Epoch 96/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5254 - accuracy: 0.7526\n",
      "Epoch 97/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5128 - accuracy: 0.7626\n",
      "Epoch 98/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5407 - accuracy: 0.7484\n",
      "Epoch 99/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5046 - accuracy: 0.7436\n",
      "Epoch 100/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5111 - accuracy: 0.7553\n",
      "5/5 [==============================] - 0s 980us/step - loss: 0.5427 - accuracy: 0.6901\n",
      "Epoch 1/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.7967 - accuracy: 0.5956\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.7777 - accuracy: 0.4230\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.7208 - accuracy: 0.4565\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6897 - accuracy: 0.5704\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6862 - accuracy: 0.5798\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6617 - accuracy: 0.6335\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6704 - accuracy: 0.6057\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6947 - accuracy: 0.5354\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6786 - accuracy: 0.5938\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6813 - accuracy: 0.5811\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6843 - accuracy: 0.5687\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6740 - accuracy: 0.6103\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6880 - accuracy: 0.5598\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6814 - accuracy: 0.5790\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6773 - accuracy: 0.5891\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6717 - accuracy: 0.6085\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7035 - accuracy: 0.5085\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6777 - accuracy: 0.6232\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6601 - accuracy: 0.6251\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6743 - accuracy: 0.6028\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6994 - accuracy: 0.5210\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6770 - accuracy: 0.6176\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6983 - accuracy: 0.5384\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6836 - accuracy: 0.5755\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6953 - accuracy: 0.5399\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6814 - accuracy: 0.5873\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6801 - accuracy: 0.5829\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.7197 - accuracy: 0.5030\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6865 - accuracy: 0.5642\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6816 - accuracy: 0.5755\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6966 - accuracy: 0.5415\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6814 - accuracy: 0.5763\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6757 - accuracy: 0.5943\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6948 - accuracy: 0.5407\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6715 - accuracy: 0.6277\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6744 - accuracy: 0.5966\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6678 - accuracy: 0.6249\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6789 - accuracy: 0.5835\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6881 - accuracy: 0.5475\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6749 - accuracy: 0.6007\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6691 - accuracy: 0.6064\n",
      "Epoch 42/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6750 - accuracy: 0.6110\n",
      "Epoch 43/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6811 - accuracy: 0.5805\n",
      "Epoch 44/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6883 - accuracy: 0.5535\n",
      "Epoch 45/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6730 - accuracy: 0.6134\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6829 - accuracy: 0.5774\n",
      "Epoch 47/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6719 - accuracy: 0.6021\n",
      "Epoch 48/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6805 - accuracy: 0.5812\n",
      "Epoch 49/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6892 - accuracy: 0.5445\n",
      "Epoch 50/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6705 - accuracy: 0.6240\n",
      "Epoch 51/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.7014 - accuracy: 0.5384\n",
      "Epoch 52/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6782 - accuracy: 0.6048\n",
      "Epoch 53/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5470\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6862 - accuracy: 0.5571\n",
      "Epoch 55/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6876 - accuracy: 0.5608\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6809 - accuracy: 0.5805\n",
      "Epoch 57/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6821 - accuracy: 0.5758\n",
      "Epoch 58/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6847 - accuracy: 0.5741\n",
      "Epoch 59/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6722 - accuracy: 0.6105\n",
      "Epoch 60/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7096 - accuracy: 0.5168\n",
      "Epoch 61/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6879 - accuracy: 0.5531\n",
      "Epoch 62/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6956 - accuracy: 0.5348\n",
      "Epoch 63/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6804 - accuracy: 0.5838\n",
      "Epoch 64/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6641 - accuracy: 0.6233\n",
      "Epoch 65/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6608 - accuracy: 0.6262\n",
      "Epoch 66/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6687 - accuracy: 0.6229\n",
      "Epoch 67/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6785 - accuracy: 0.5951\n",
      "Epoch 68/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6826 - accuracy: 0.5734\n",
      "Epoch 69/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6865 - accuracy: 0.5591\n",
      "Epoch 70/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6908 - accuracy: 0.5543\n",
      "Epoch 71/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.5404\n",
      "Epoch 72/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6910 - accuracy: 0.5446\n",
      "Epoch 73/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6774 - accuracy: 0.5908\n",
      "Epoch 74/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6882 - accuracy: 0.5592\n",
      "Epoch 75/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6833 - accuracy: 0.5725\n",
      "Epoch 76/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6556 - accuracy: 0.6600\n",
      "Epoch 77/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6716 - accuracy: 0.6001\n",
      "Epoch 78/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6845 - accuracy: 0.5738\n",
      "Epoch 79/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6740 - accuracy: 0.6086\n",
      "Epoch 80/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6725 - accuracy: 0.6016\n",
      "Epoch 81/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.6891 - accuracy: 0.5499\n",
      "Epoch 82/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6791 - accuracy: 0.5921\n",
      "Epoch 83/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6819 - accuracy: 0.5762\n",
      "Epoch 84/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6768 - accuracy: 0.5877\n",
      "Epoch 85/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6832 - accuracy: 0.5728\n",
      "Epoch 86/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6908 - accuracy: 0.5520\n",
      "Epoch 87/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6729 - accuracy: 0.6031\n",
      "Epoch 88/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6863 - accuracy: 0.5602\n",
      "Epoch 89/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6855 - accuracy: 0.5625\n",
      "Epoch 90/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6868 - accuracy: 0.5559\n",
      "Epoch 91/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6701 - accuracy: 0.6079\n",
      "Epoch 92/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6721 - accuracy: 0.6039\n",
      "Epoch 93/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6740 - accuracy: 0.6105\n",
      "Epoch 94/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6734 - accuracy: 0.5950\n",
      "Epoch 95/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6834 - accuracy: 0.5665\n",
      "Epoch 96/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6874 - accuracy: 0.5601\n",
      "Epoch 97/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6805 - accuracy: 0.5764\n",
      "Epoch 98/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6819 - accuracy: 0.5663\n",
      "Epoch 99/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6801 - accuracy: 0.5659\n",
      "Epoch 100/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6853 - accuracy: 0.5180\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7166 - accuracy: 0.4857\n",
      "Epoch 1/80\n",
      "5/5 [==============================] - 1s 1ms/step - loss: 0.8089 - accuracy: 0.5008\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.8074 - accuracy: 0.5058\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7688 - accuracy: 0.4984\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7047 - accuracy: 0.4790\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7156 - accuracy: 0.5267\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6922 - accuracy: 0.5495\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6948 - accuracy: 0.5223\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6989 - accuracy: 0.5107\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7065 - accuracy: 0.5176\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6974 - accuracy: 0.5126\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6952 - accuracy: 0.4928\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5310\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6981 - accuracy: 0.4859\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6999 - accuracy: 0.5285\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6895 - accuracy: 0.5236\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6958 - accuracy: 0.4229\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6961 - accuracy: 0.4776\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6943 - accuracy: 0.4997\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.5280\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6979 - accuracy: 0.4983\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6937 - accuracy: 0.4428\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6954 - accuracy: 0.4310\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6916 - accuracy: 0.5076\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6934 - accuracy: 0.5220\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6984 - accuracy: 0.4007\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6949 - accuracy: 0.5111\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7109 - accuracy: 0.4859\n",
      "Epoch 28/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6886 - accuracy: 0.5341\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6959 - accuracy: 0.4685\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6968 - accuracy: 0.4903\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6922 - accuracy: 0.5059\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6979 - accuracy: 0.5042\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6924 - accuracy: 0.5181\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6879 - accuracy: 0.5484\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6901 - accuracy: 0.5236\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6921 - accuracy: 0.5045\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6909 - accuracy: 0.5042\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6909 - accuracy: 0.5285\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6868 - accuracy: 0.5415\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6910 - accuracy: 0.5783\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6999 - accuracy: 0.4935\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6918 - accuracy: 0.5093\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6898 - accuracy: 0.5454\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6872 - accuracy: 0.5380\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6958 - accuracy: 0.5084\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6921 - accuracy: 0.4720\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6913 - accuracy: 0.5120\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6880 - accuracy: 0.5484\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6914 - accuracy: 0.4933\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6934 - accuracy: 0.5086\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6915 - accuracy: 0.5524\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6778 - accuracy: 0.5801\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6863 - accuracy: 0.5707\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6910 - accuracy: 0.5067\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6869 - accuracy: 0.6526\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6815 - accuracy: 0.5541\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6854 - accuracy: 0.5845\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6986 - accuracy: 0.4337\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6878 - accuracy: 0.5454\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6854 - accuracy: 0.6282\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6866 - accuracy: 0.5636\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6768 - accuracy: 0.5635\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6930 - accuracy: 0.4837\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6886 - accuracy: 0.5173\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6815 - accuracy: 0.5742\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6798 - accuracy: 0.5502\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6836 - accuracy: 0.5791\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6757 - accuracy: 0.5432\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6712 - accuracy: 0.6200\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6911 - accuracy: 0.4828\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6765 - accuracy: 0.5897\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7059 - accuracy: 0.5050\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6709 - accuracy: 0.5366\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6769 - accuracy: 0.5641\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6752 - accuracy: 0.5416\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6854 - accuracy: 0.4953\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6661 - accuracy: 0.6568\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6603 - accuracy: 0.5724\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6779 - accuracy: 0.6464\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6438 - accuracy: 0.7306\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.8602 - accuracy: 0.3239\n",
      "Epoch 1/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7196 - accuracy: 0.5190\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6907 - accuracy: 0.5351\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7283 - accuracy: 0.5793\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7324 - accuracy: 0.4173\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6921 - accuracy: 0.6110\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6902 - accuracy: 0.5888\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6884 - accuracy: 0.6342\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6873 - accuracy: 0.5997\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6839 - accuracy: 0.5758\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6808 - accuracy: 0.5875\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6838 - accuracy: 0.5754\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6783 - accuracy: 0.6001\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6952 - accuracy: 0.5445\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6917 - accuracy: 0.5506\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6729 - accuracy: 0.6062\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6662 - accuracy: 0.6110\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6789 - accuracy: 0.6010\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6803 - accuracy: 0.5923\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6832 - accuracy: 0.5710\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6851 - accuracy: 0.5649\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6756 - accuracy: 0.5949\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6727 - accuracy: 0.6083\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7012 - accuracy: 0.4917\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6841 - accuracy: 0.6175\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7012 - accuracy: 0.5610\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6827 - accuracy: 0.5741\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6894 - accuracy: 0.5354\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6811 - accuracy: 0.5884\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6950 - accuracy: 0.5662\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6920 - accuracy: 0.5515\n",
      "Epoch 31/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6817 - accuracy: 0.5758\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6785 - accuracy: 0.5975\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6964 - accuracy: 0.5584\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6844 - accuracy: 0.5662\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6779 - accuracy: 0.5832\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5493\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6771 - accuracy: 0.5875\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6749 - accuracy: 0.5893\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6795 - accuracy: 0.5836\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6853 - accuracy: 0.5606\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6793 - accuracy: 0.5745\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6808 - accuracy: 0.5797\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6894 - accuracy: 0.5489\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6845 - accuracy: 0.5493\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6812 - accuracy: 0.5819\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6774 - accuracy: 0.5836\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6707 - accuracy: 0.6031\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6762 - accuracy: 0.5862\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6722 - accuracy: 0.6097\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.6598 - accuracy: 0.6274\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6903 - accuracy: 0.5463\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6785 - accuracy: 0.6205\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6702 - accuracy: 0.5936\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6729 - accuracy: 0.6140\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6771 - accuracy: 0.5832\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6788 - accuracy: 0.5702\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6879 - accuracy: 0.5502\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6780 - accuracy: 0.5797\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6728 - accuracy: 0.5836\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6691 - accuracy: 0.5940\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6952 - accuracy: 0.4668\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6729 - accuracy: 0.5793\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6683 - accuracy: 0.5940\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6714 - accuracy: 0.5788\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6667 - accuracy: 0.6123\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6598 - accuracy: 0.6001\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6646 - accuracy: 0.6068\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6640 - accuracy: 0.6429\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6892 - accuracy: 0.5636\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6715 - accuracy: 0.6205\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6626 - accuracy: 0.5741\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6975 - accuracy: 0.5449\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6545 - accuracy: 0.6107\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6632 - accuracy: 0.5826\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6571 - accuracy: 0.6033\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6378 - accuracy: 0.6044\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6474 - accuracy: 0.6615\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6403 - accuracy: 0.6157\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7055 - accuracy: 0.5495\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6913 - accuracy: 0.5597\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.6681 - accuracy: 0.5775\n",
      "Epoch 1/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.8688 - accuracy: 0.4741\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7114 - accuracy: 0.6000\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6674 - accuracy: 0.6079\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7505 - accuracy: 0.4382\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6985 - accuracy: 0.4949\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6885 - accuracy: 0.5788\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7011 - accuracy: 0.5553\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6849 - accuracy: 0.5671\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6827 - accuracy: 0.5718\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6744 - accuracy: 0.5983\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6876 - accuracy: 0.5601\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6765 - accuracy: 0.6092\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6786 - accuracy: 0.5888\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6761 - accuracy: 0.5940\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6877 - accuracy: 0.5545\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6832 - accuracy: 0.5679\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6863 - accuracy: 0.5705\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6916 - accuracy: 0.5584\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6703 - accuracy: 0.6148\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6796 - accuracy: 0.5822\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6868 - accuracy: 0.5571\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6797 - accuracy: 0.5901\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5588\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6903 - accuracy: 0.5519\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6839 - accuracy: 0.5671\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6891 - accuracy: 0.5588\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6784 - accuracy: 0.5848\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6729 - accuracy: 0.6039\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6757 - accuracy: 0.6092\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6791 - accuracy: 0.6026\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6799 - accuracy: 0.5831\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6762 - accuracy: 0.5922\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6821 - accuracy: 0.5740\n",
      "Epoch 34/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6754 - accuracy: 0.6105\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6854 - accuracy: 0.5636\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6907 - accuracy: 0.5432\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6800 - accuracy: 0.5870\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6860 - accuracy: 0.5762\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6700 - accuracy: 0.6126\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6899 - accuracy: 0.5558\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6839 - accuracy: 0.5927\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6860 - accuracy: 0.5705\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6984 - accuracy: 0.5449\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6847 - accuracy: 0.5684\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6799 - accuracy: 0.5792\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6788 - accuracy: 0.5827\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6777 - accuracy: 0.5840\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6716 - accuracy: 0.6035\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6717 - accuracy: 0.5961\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6845 - accuracy: 0.5605\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6871 - accuracy: 0.5362\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6786 - accuracy: 0.5901\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7116 - accuracy: 0.5354\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6805 - accuracy: 0.5775\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6794 - accuracy: 0.5753\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6785 - accuracy: 0.5788\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6836 - accuracy: 0.5675\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7014 - accuracy: 0.5310\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6817 - accuracy: 0.5692\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6906 - accuracy: 0.5293\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6863 - accuracy: 0.5645\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6663 - accuracy: 0.6039\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6811 - accuracy: 0.5688\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6813 - accuracy: 0.5584\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6800 - accuracy: 0.5775\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6743 - accuracy: 0.5857\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6814 - accuracy: 0.5601\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6708 - accuracy: 0.6052\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6743 - accuracy: 0.5844\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6664 - accuracy: 0.6009\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6895 - accuracy: 0.5523\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6827 - accuracy: 0.5688\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6825 - accuracy: 0.5410\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6692 - accuracy: 0.6031\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6732 - accuracy: 0.5809\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6850 - accuracy: 0.6510\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6753 - accuracy: 0.6213\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6533 - accuracy: 0.6226\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6614 - accuracy: 0.6070\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6999 - accuracy: 0.4051\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.6849 - accuracy: 0.5000\n",
      "Epoch 1/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7707 - accuracy: 0.5276\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7114 - accuracy: 0.4858\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7242 - accuracy: 0.5298\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7300 - accuracy: 0.4608\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7157 - accuracy: 0.5189\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7106 - accuracy: 0.5007\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7124 - accuracy: 0.5289\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6980 - accuracy: 0.4832\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7210 - accuracy: 0.4607\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6948 - accuracy: 0.4756\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6971 - accuracy: 0.5246\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6925 - accuracy: 0.4985\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6923 - accuracy: 0.5094\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.5202\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5428\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6925 - accuracy: 0.5107\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6966 - accuracy: 0.4829\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6910 - accuracy: 0.5315\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6921 - accuracy: 0.5168\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6903 - accuracy: 0.5645\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6907 - accuracy: 0.5263\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6928 - accuracy: 0.4680\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6910 - accuracy: 0.5637\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6936 - accuracy: 0.5194\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6973 - accuracy: 0.5107\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6944 - accuracy: 0.5039\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6912 - accuracy: 0.5037\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6907 - accuracy: 0.5411\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6876 - accuracy: 0.5359\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6909 - accuracy: 0.6322\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6897 - accuracy: 0.5854\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6939 - accuracy: 0.5250\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6955 - accuracy: 0.4951\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6901 - accuracy: 0.5419\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6983 - accuracy: 0.4031\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.5157\n",
      "Epoch 37/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6937 - accuracy: 0.5168\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6870 - accuracy: 0.5354\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6896 - accuracy: 0.5467\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6906 - accuracy: 0.5421\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6898 - accuracy: 0.5215\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6923 - accuracy: 0.4972\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6888 - accuracy: 0.5306\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.5033\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6873 - accuracy: 0.5874\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6873 - accuracy: 0.6222\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6862 - accuracy: 0.5372\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6898 - accuracy: 0.5221\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6923 - accuracy: 0.4750\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6836 - accuracy: 0.6623\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6854 - accuracy: 0.5346\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6818 - accuracy: 0.5356\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6856 - accuracy: 0.5297\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6915 - accuracy: 0.5697\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7104 - accuracy: 0.4903\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6822 - accuracy: 0.5719\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6845 - accuracy: 0.5904\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6873 - accuracy: 0.4876\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6843 - accuracy: 0.6114\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6833 - accuracy: 0.5354\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6817 - accuracy: 0.5250\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6852 - accuracy: 0.4669\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6813 - accuracy: 0.5472\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.6771 - accuracy: 0.6000\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6741 - accuracy: 0.6000\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6845 - accuracy: 0.5582\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6761 - accuracy: 0.5787\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6922 - accuracy: 0.4683\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6757 - accuracy: 0.5833\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6750 - accuracy: 0.5305\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6670 - accuracy: 0.5835\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6636 - accuracy: 0.6386\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6582 - accuracy: 0.6273\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6486 - accuracy: 0.7261\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6436 - accuracy: 0.6793\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6708 - accuracy: 0.5623\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6520 - accuracy: 0.6500\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6458 - accuracy: 0.5917\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6339 - accuracy: 0.6498\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6394 - accuracy: 0.6687\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6366 - accuracy: 0.6065\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6252 - accuracy: 0.6963\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6306 - accuracy: 0.6462\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6185 - accuracy: 0.7029\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5963 - accuracy: 0.6765\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6191 - accuracy: 0.6607\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6280 - accuracy: 0.6205\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6292 - accuracy: 0.6579\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6254 - accuracy: 0.6234\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5697 - accuracy: 0.7223\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5751 - accuracy: 0.7032\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5904 - accuracy: 0.7146\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5800 - accuracy: 0.6923\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5807 - accuracy: 0.6924\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5775 - accuracy: 0.6496\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5454 - accuracy: 0.6996\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5313 - accuracy: 0.7295\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5573 - accuracy: 0.6993\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5375 - accuracy: 0.7471\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5614 - accuracy: 0.7051\n",
      "WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_test_function.<locals>.test_function at 0x1535959d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.5818 - accuracy: 0.7324\n",
      "Epoch 1/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7894 - accuracy: 0.5446\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7691 - accuracy: 0.4355\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6982 - accuracy: 0.5749\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6949 - accuracy: 0.5797\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6905 - accuracy: 0.5958\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6904 - accuracy: 0.5419\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6683 - accuracy: 0.6192\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6946 - accuracy: 0.4905\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6888 - accuracy: 0.5988\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6906 - accuracy: 0.5654\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6710 - accuracy: 0.6079\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6901 - accuracy: 0.5706\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6814 - accuracy: 0.5832\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6816 - accuracy: 0.5780\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6849 - accuracy: 0.5654\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6809 - accuracy: 0.5884\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6626 - accuracy: 0.6209\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7047 - accuracy: 0.4485\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7009 - accuracy: 0.4994\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6902 - accuracy: 0.5780\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6627 - accuracy: 0.6196\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6758 - accuracy: 0.5927\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6844 - accuracy: 0.5702\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6899 - accuracy: 0.5445\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6884 - accuracy: 0.5662\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6695 - accuracy: 0.6136\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6987 - accuracy: 0.5480\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6846 - accuracy: 0.5858\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6902 - accuracy: 0.5528\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7076 - accuracy: 0.5398\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6805 - accuracy: 0.5884\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6762 - accuracy: 0.5884\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6752 - accuracy: 0.6070\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6805 - accuracy: 0.5819\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6864 - accuracy: 0.5571\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6838 - accuracy: 0.5632\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6903 - accuracy: 0.5606\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6820 - accuracy: 0.5784\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6761 - accuracy: 0.5927\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6796 - accuracy: 0.5836\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6840 - accuracy: 0.5684\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6907 - accuracy: 0.5528\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6759 - accuracy: 0.5975\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6728 - accuracy: 0.5979\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6794 - accuracy: 0.5797\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6898 - accuracy: 0.5506\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6900 - accuracy: 0.5320\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6803 - accuracy: 0.5845\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6811 - accuracy: 0.5880\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6730 - accuracy: 0.6083\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6760 - accuracy: 0.5888\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6635 - accuracy: 0.6196\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6652 - accuracy: 0.6183\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6821 - accuracy: 0.5940\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6844 - accuracy: 0.5432\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6804 - accuracy: 0.5866\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6776 - accuracy: 0.5923\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6890 - accuracy: 0.5528\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6838 - accuracy: 0.5493\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6723 - accuracy: 0.6274\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6785 - accuracy: 0.5862\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6876 - accuracy: 0.5462\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6775 - accuracy: 0.5606\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6910 - accuracy: 0.5636\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6800 - accuracy: 0.5793\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6753 - accuracy: 0.5949\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6863 - accuracy: 0.5393\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6752 - accuracy: 0.5771\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6672 - accuracy: 0.5962\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6855 - accuracy: 0.5664\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6717 - accuracy: 0.6214\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6964 - accuracy: 0.5636\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6777 - accuracy: 0.6765\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6708 - accuracy: 0.5875\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6714 - accuracy: 0.5910\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6811 - accuracy: 0.5654\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6738 - accuracy: 0.6084\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6683 - accuracy: 0.5940\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6691 - accuracy: 0.5754\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6640 - accuracy: 0.5797\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6601 - accuracy: 0.6516\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6628 - accuracy: 0.5610\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6447 - accuracy: 0.6151\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6519 - accuracy: 0.6405\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6374 - accuracy: 0.5999\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6844 - accuracy: 0.5383\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7010 - accuracy: 0.6079\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6689 - accuracy: 0.5911\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6542 - accuracy: 0.6202\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6719 - accuracy: 0.5692\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6385 - accuracy: 0.7091\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6520 - accuracy: 0.6200\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6429 - accuracy: 0.6703\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6260 - accuracy: 0.6899\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6317 - accuracy: 0.6234\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6226 - accuracy: 0.7030\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6451 - accuracy: 0.6333\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6718 - accuracy: 0.5759\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.7191 - accuracy: 0.5411\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6489 - accuracy: 0.6120\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x154976ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6314 - accuracy: 0.6479\n",
      "Epoch 1/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7875 - accuracy: 0.4859\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.7843 - accuracy: 0.5757\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7461 - accuracy: 0.4195\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6906 - accuracy: 0.5857\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7001 - accuracy: 0.5744\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6787 - accuracy: 0.5848\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6860 - accuracy: 0.5844\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6810 - accuracy: 0.5866\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6833 - accuracy: 0.5822\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6819 - accuracy: 0.5779\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6750 - accuracy: 0.6096\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6846 - accuracy: 0.5753\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6848 - accuracy: 0.5762\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6778 - accuracy: 0.6013\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6700 - accuracy: 0.6079\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6869 - accuracy: 0.5631\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6809 - accuracy: 0.5866\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6778 - accuracy: 0.5862\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6816 - accuracy: 0.5792\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6815 - accuracy: 0.5822\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6743 - accuracy: 0.6039\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6789 - accuracy: 0.5848\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6994 - accuracy: 0.5406\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6775 - accuracy: 0.5953\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.5540\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6780 - accuracy: 0.6460\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6852 - accuracy: 0.5705\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6783 - accuracy: 0.5935\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6939 - accuracy: 0.5406\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6788 - accuracy: 0.5901\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6855 - accuracy: 0.5662\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6802 - accuracy: 0.5848\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6792 - accuracy: 0.5827\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6948 - accuracy: 0.5358\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6760 - accuracy: 0.6083\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6861 - accuracy: 0.5727\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6836 - accuracy: 0.5727\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6849 - accuracy: 0.5727\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6853 - accuracy: 0.5475\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6781 - accuracy: 0.5957\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6930 - accuracy: 0.5636\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6913 - accuracy: 0.5393\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6760 - accuracy: 0.5970\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6679 - accuracy: 0.6135\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6879 - accuracy: 0.5666\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6951 - accuracy: 0.5293\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6883 - accuracy: 0.5228\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6809 - accuracy: 0.5862\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5740\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6744 - accuracy: 0.5905\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6841 - accuracy: 0.5679\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6821 - accuracy: 0.5762\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6784 - accuracy: 0.5822\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6734 - accuracy: 0.5979\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6768 - accuracy: 0.5862\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6947 - accuracy: 0.5441\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6777 - accuracy: 0.5953\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6808 - accuracy: 0.5723\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6781 - accuracy: 0.5822\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6847 - accuracy: 0.5658\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6893 - accuracy: 0.5497\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6844 - accuracy: 0.5653\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6762 - accuracy: 0.5888\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6860 - accuracy: 0.5640\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6848 - accuracy: 0.5584\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6763 - accuracy: 0.5857\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6734 - accuracy: 0.5922\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6771 - accuracy: 0.5809\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6703 - accuracy: 0.6152\n",
      "Epoch 70/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6896 - accuracy: 0.5436\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6797 - accuracy: 0.5658\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6766 - accuracy: 0.5905\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6756 - accuracy: 0.5827\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6906 - accuracy: 0.5371\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6837 - accuracy: 0.5414\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6936 - accuracy: 0.5414\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6776 - accuracy: 0.5744\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6686 - accuracy: 0.6061\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6923 - accuracy: 0.5471\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6775 - accuracy: 0.5662\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6750 - accuracy: 0.5697\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6631 - accuracy: 0.6096\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6811 - accuracy: 0.5540\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6734 - accuracy: 0.5848\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6682 - accuracy: 0.5888\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6981 - accuracy: 0.5587\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6722 - accuracy: 0.6306\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6752 - accuracy: 0.5770\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6713 - accuracy: 0.6028\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6714 - accuracy: 0.5921\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6586 - accuracy: 0.6113\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6634 - accuracy: 0.5833\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6674 - accuracy: 0.6056\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6529 - accuracy: 0.6142\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6607 - accuracy: 0.6611\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6701 - accuracy: 0.5546\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6618 - accuracy: 0.5840\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6742 - accuracy: 0.5561\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6624 - accuracy: 0.6630\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6492 - accuracy: 0.5870\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x1549c43a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6573 - accuracy: 0.5714\n",
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7306 - accuracy: 0.5723\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7351 - accuracy: 0.4425\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6873 - accuracy: 0.5489\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6909 - accuracy: 0.5344\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6893 - accuracy: 0.5619\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7011 - accuracy: 0.5044\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7267 - accuracy: 0.5981\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7205 - accuracy: 0.4669\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7014 - accuracy: 0.4885\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7056 - accuracy: 0.5429\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6971 - accuracy: 0.5232\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.4746\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6880 - accuracy: 0.5828\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7085 - accuracy: 0.5128\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6914 - accuracy: 0.5340\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6855 - accuracy: 0.5757\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6925 - accuracy: 0.5420\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6858 - accuracy: 0.5771\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6875 - accuracy: 0.5613\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6815 - accuracy: 0.5887\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6879 - accuracy: 0.5507\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6897 - accuracy: 0.5564\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6905 - accuracy: 0.5363\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6886 - accuracy: 0.5491\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6936 - accuracy: 0.5283\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6856 - accuracy: 0.5597\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6849 - accuracy: 0.5621\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6914 - accuracy: 0.5315\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6908 - accuracy: 0.5315\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6949 - accuracy: 0.5212\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6834 - accuracy: 0.5705\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6889 - accuracy: 0.5431\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6916 - accuracy: 0.5240\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6914 - accuracy: 0.5470\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6937 - accuracy: 0.5329\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6868 - accuracy: 0.5516\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6880 - accuracy: 0.5549\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6884 - accuracy: 0.5402\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7000 - accuracy: 0.4914\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6870 - accuracy: 0.5453\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6834 - accuracy: 0.5609\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6864 - accuracy: 0.5782\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6849 - accuracy: 0.5580\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6871 - accuracy: 0.5440\n",
      "Epoch 45/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6880 - accuracy: 0.5376\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6903 - accuracy: 0.5134\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6920 - accuracy: 0.5206\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6902 - accuracy: 0.5198\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6870 - accuracy: 0.5306\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6788 - accuracy: 0.5647\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6850 - accuracy: 0.5487\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6832 - accuracy: 0.5606\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6831 - accuracy: 0.5468\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6764 - accuracy: 0.5636\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6718 - accuracy: 0.5831\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6723 - accuracy: 0.7008\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6767 - accuracy: 0.5893\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6748 - accuracy: 0.6107\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6636 - accuracy: 0.6651\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6612 - accuracy: 0.5915\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6702 - accuracy: 0.5414\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6958 - accuracy: 0.5682\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6806 - accuracy: 0.4993\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6534 - accuracy: 0.6353\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6497 - accuracy: 0.6232\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6411 - accuracy: 0.6763\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6175 - accuracy: 0.6796\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6399 - accuracy: 0.6462\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6514 - accuracy: 0.6351\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6110 - accuracy: 0.6871\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6464 - accuracy: 0.6087\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5956 - accuracy: 0.6955\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6171 - accuracy: 0.6756\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5834 - accuracy: 0.7119\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5471 - accuracy: 0.7643\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5522 - accuracy: 0.7184\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5768 - accuracy: 0.6533\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5566 - accuracy: 0.7461\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5835 - accuracy: 0.6623\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5620 - accuracy: 0.7148\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5455 - accuracy: 0.7335\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5747 - accuracy: 0.6898\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5590 - accuracy: 0.7095\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5502 - accuracy: 0.7245\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5498 - accuracy: 0.6986\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5767 - accuracy: 0.7181\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5392 - accuracy: 0.7294\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5874 - accuracy: 0.6818\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5032 - accuracy: 0.7542\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5328 - accuracy: 0.7377\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5284 - accuracy: 0.7271\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5432 - accuracy: 0.7241\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5774 - accuracy: 0.6886\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5094 - accuracy: 0.7400\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6979 - accuracy: 0.6129\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4784 - accuracy: 0.7928\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4893 - accuracy: 0.7841\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5443 - accuracy: 0.7427\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5675 - accuracy: 0.6805\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5667 - accuracy: 0.6979\n"
     ]
    }
   ],
   "source": [
    "grid_result = gs.fit(X_train, Y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.6505700945854187 using {'batch_size': 32, 'epochs': 100}\n",
      "Means: 0.5798792839050293, Stdev: 0.04673669396796675 with: {'batch_size': 15, 'epochs': 80}\n",
      "Means: 0.6313883364200592, Stdev: 0.10364706217658982 with: {'batch_size': 15, 'epochs': 100}\n",
      "Means: 0.4671361446380615, Stdev: 0.1060762614023109 with: {'batch_size': 32, 'epochs': 80}\n",
      "Means: 0.6505700945854187, Stdev: 0.06574136323812287 with: {'batch_size': 32, 'epochs': 100}\n"
     ]
    }
   ],
   "source": [
    "# your grid_result object should be able to run in this code \n",
    "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's interesting that the model actually got better accuracy with fewer epochs showing that less is sometimes more!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
